Fold,No. conv layers,Hidden size,Learning rate,Learning rate decay,Weight decay,Step size,Avg. F1,Loss
fold0,3,512,0.0007611780268035202,0.886169275324013,0.014590598304727581,10,1.0,7.621327741236107e-08
fold1,3,512,0.0007611780268035202,0.886169275324013,0.014590598304727581,10,1.0,1.0078234617817392e-11
fold2,3,512,0.0007611780268035202,0.886169275324013,0.014590598304727581,10,1.0,1.2805772872261378e-06
fold0,8,128,3.7943438864778095e-05,0.1567127947383217,0.010680361158155703,10,0.996402222106604,0.00945874530723757
fold1,8,128,3.7943438864778095e-05,0.1567127947383217,0.010680361158155703,10,1.0,0.00012039078965394448
fold2,8,128,3.7943438864778095e-05,0.1567127947383217,0.010680361158155703,10,0.9976703014084504,0.007197849572254
fold0,8,1024,3.969075055201033e-05,0.9206169027986946,0.0360556749999692,50,1.0,1.7982559667499637e-08
fold1,8,1024,3.969075055201033e-05,0.9206169027986946,0.0360556749999692,50,1.0,8.523950329177783e-11
